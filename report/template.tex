% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{urban-formatting}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

% urban-short-report.tex
% v1.0 Dec. 2021

%\documentclass{urban-formatting}

% Font and Font Weight
\usepackage[default]{lato}
\usepackage[T1]{fontenc}

% Setting the references list
\bibliography{references}

% Change out report title - use shortened title if necessary
\title{REPORT TITLE HERE: USE A SHORTENED TITLE IF NECESSARY}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[boxrule=0pt, sharp corners, interior hidden, enhanced, frame hidden, breakable, borderline west={3pt}{0pt}{shadecolor}]}{\end{tcolorbox}}\fi

\pagenumbering{roman}

\begin{titlepage}
    % Add Policy Center/Intaitive/Toxonmy Term Bar
    % note the textbox exceeds width of document to avoid white space on sides
    \begin{textblock*}{9in}(-0.25in, 0.15in)
        \begin{tcolorbox}[valign = center]
            \begin{center}
                \policycenter{Research Methods and Data Analytics}
            \end{center}
        \end{tcolorbox}
    \end{textblock*}

    % Adding the cover image - code forces the image to be width of full paper (ignoring margins)
    \vspace*{-1.7cm}
    \noindent
    \makebox[\textwidth]{\includegraphics{images/cover.jpg}}
    
    \vspace{0.35in}
    \noindent\textcolor{urban-blue}{\MakeUppercase{\textbf{Research Report}}}
    
    \titlereport{Opt-In Statistical Disclosure Protections}
    
    \vspace{-0.25in}
    
    \reportsubtitle{Empowering Survey Respondents to Improve Data Quality}
    % Multiple column author names - change the "4" to the number of desired columns
    \begin{multicols}{4}
        \authorfont{Aaron R. Williams}
        
        \authorfont{Jennifer Andre}
      
    \end{multicols}
    
    \vspace{-0.75cm}
    
    \datefont{August 2023}

    % Add logo
    \begin{textblock*}{4.5in}[1, 1](5.5in, 10.5in)
        \noindent\includegraphics[width=4.5in]{images/cover-footer.jpg}
    \end{textblock*}
\end{titlepage}

\include{frontmatter/about}

\cleardoublepage

\setcounter{page}{3}
\begin{singlespace}
    \tableofcontents
\end{singlespace}

\thispagestyle{empty}

\include{frontmatter/acknowledgements}

\include{frontmatter/executive}

\part{Opt-In Statistical Disclosure Protections}

\section{Introduction}

People generate and share data about themselves every day when they
browse the web, purchase goods and services, and respond to surveys, and
they should be empowered to make decisions about how these data are
accessed and used. Currently, disclosure protection policies at the US
Census Bureau do not allow for such empowerment -- respondents to
surveys like the decennial census and the American Community Survey are
all subjected to disclosure protections. Data for all respondents are,
by default, masked with some form of statistical disclosure control, and
those who may wish to see themselves accurately reflected in the data
are unable to do so. These data quality distortions may have greater
impact for certain groups, such as smaller race and ethnicity groups,
relative to others.

In this brief, we explore a new framework for disclosure protections
that would require respondents to actively opt in to disclosure
protections. Responses for those who opt in would be treated with
disclosure protections, while responses for those who forego protections
would remain unchanged in statistical product outputs. We present two
demonstration studies, the first using an opt-in local differential
privacy approach for the decennial census, and the second using an
opt-in synthetic data approach for the American Community Survey. In
both cases, we seek to explore the impact of varying the rate of opting
in to disclosure protections on data quality, along with the associated
privacy consequences. We especially examine the impact for small
racial/ethnic groups, including the impact on quality and privacy if
some groups opt in at higher rates than others.

We aim to test the feasibility of this potential solution path,
contributing to ongoing public discussions and debate about disclosure
protections and public data quality involving researchers, public data
users, and other stakeholders. This solution would have wide-ranging
implications, including operational changes, new outreach strategies,
and many complex legal questions about Title 13 and other regulations.
The findings we present here provide early evidence on the impact of
turning privacy disclosure choices over to participants.

\section{Background}

\subsection{Data Privacy}

Utility \& privacy tradeoff

Formal privacy/DP

Privacy loss budget

Traditional SDC

Synthetic data

\subsection{The US Census Bureau and Disclosure Avoidance}

The US Census Bureau is tasked with providing high quality data about
the US and its people. These data are of enormous consequence for the
public, serving as the basis for political representation, community
funding and planning, and key research. Given these use cases, the
accuracy and quality of Census Bureau products is crucial.

Decennial census statistical products are used for congressional
apportionment, redistricting, federal funding allocations, planning and
decision-making for government and business organizations, and informing
many other surveys (Mather and Scommegna 2019). The American Community
Survey (ACS) is used to inform federal agencies for policymaking and
program delivery, state and local agencies for services like roads and
schools, and nongovernmental organizations for research and analysis
(United States Census Bureau 2017). In fiscal year 2015, 132 federal
programs used Census Bureau data to allocate more than \$675 billion in
funds to state and local communities (Hotchkiss and Phelan 2017).
Decennial census and ACS data are also foundational to racial equity
analytics, enabling researchers to answer important research and policy
questions (Axelrod, Ramos, and Bullied 2022).

In addition to conducting surveys and releasing high quality public
data, the Census Bureau is also obligated to protect the confidentiality
of individual respondents reflected in these data products. The Census
Bureau's approach to safeguarding the identities of respondents in
publicly released data is informed by its interpretation of Section 9 of
Title 13 of the U.S. Code, enacted in 1954. This approach has evolved
over the years, especially in response to advances in computing
technologies and attack methods (Hotz and Salvo 2022). In 2018, the
Census Bureau announced its intention to ``modernize how we protect
respondent confidentiality,'' including the adoption of Differential
Privacy (DP) (J. M. Abowd 2018). This move was motivated by certain
benefits of DP over traditional disclosure limitation, including more
robust protections and greater transparency (J. Abowd et al. 2022).

For the 2020 Decennial Census, the Census Bureau updated their
Disclosure Avoidance System (DAS) from traditional swapping algorithms
to the differentially private TopDown Algorithm (TDA) (Bowen, Williams,
and Pickens 2022). As a formally private method, the privacy protections
can be quantified. In contrast, the Census Bureau has conceded that the
``science does not yet exist to comprehensively implement a formally
private solution for the ACS'' (Daily 2022). Instead, they are currently
exploring the feasibility of a fully synthetic public-use microdata file
and accompanying validation server. In both cases, all respondents are
subjected to disclosure protections, even those who might otherwise
prefer to see their data accurately reflected.

\section{Opt-In Privacy Framework and Implications}

In our demonstrations, we imagine a framework for disclosure protection
in which respondents would be asked to actively opt in to statistical
disclosure control methods. Those who do not opt-in would simply
contribute their true data to statistical products. We make various
simplifying assumptions and decisions, described in detail later in this
report.~

Such a change in framework would have significant legal ramifications
such as X, Y, Z.~

There are also various ethical considerations. For one, an opt-in
framework would require significant outreach efforts and plain-language
explanations to ensure that respondents understand what they are or are
not opting into. Further, careful attention must be paid to the impact
of one respondent choosing to forego protections on the privacy risks of
respondents who do opt in.~

\section{Demonstration 1: Local Differential Privacy for the Decennial Census}

The Census Bureau deployment of DP for the 2020 Decennial Census uses a
global privacy approach in which tabulated cells of confidential
responses in a series of data tables are infused with noise by a central
curator (the Census Bureau). All census respondents are automatically
subjected to the DAS, even those who might otherwise wish to see their
data reflected accurately, without any noise. Further, the noise that is
injected into tabulated data cells is independent of the size of the
population in the cell. In effect, there is more relative error added
for small groups than for larger ones. This could lead to worse data
quality for small groups such as some racial/ethnic groups and, as a
result of inaccurate representation in the data, these groups could
receive inadequate funding and incorrect research findings.~

A primary benefit of a formal privacy approach like the DAS is that the
overall privacy loss budget can be transparently quantified with the
metric \(\epsilon\). Further, the mathematical properties of DP allow
for some individuals to forego privacy protections without decreasing
other respondents' protections.~

\subsection{Local Differential Privacy}

To allow for individual-level opt-in, we move from a central DP
approach, in which the Census Bureau as a data curator would add noise
to all respondents, to a local DP approach, allowing for some
respondents to opt in and others to forego disclosure protections.
Typically, a local model assumes that a central curator cannot be
trusted, and so a respondent adds noise to their data before sending it
to the curator. For this use case, we can imagine a slight variation on
this approach in which the trusted Census Bureau still receives all data
in its confidential form, and then infuses noise only for respondents
who opt in.~

Many local DP mechanisms are based on the concept of Randomized
Response, first proposed by S. L. Warner in 1965 (Warner 1965). The
central idea is that a survey respondent flips a coin, and the result of
the coin flips determines if they answer a yes/no question with the true
answer or not. The randomization of the coin flip infuses the noise that
grants disclosure protections (Near and Abuah 2022).

We use Generalized Random Response (GRR) for our use case, allowing us
to move from a binary coin flip to a setting with higher cardinality.
With GRR, we turn the entire domain of potential responses into a
histogram and randomly switch observations based on a rate determined by
the privacy loss budget, \(\epsilon\). We then tabulate a resulting
histogram of counts and apply an adjustment to account for the randomly
perturbed responses (Wang et al. 2020).

\subsection{Data}

For this demonstration, we use person-level records from the 2010
Decennial Census Stateside Public Use Microdata Sample. This sample
contains records representing 10 percent of housing units, and the
people residing in them, along with 10 percent of people living in group
quarters. We restrict our sample to Washington, DC and Iowa because the
former has two large racial/ethnic groups, while the latter is more
homogeneous. These data contain demographic and household
characteristics about respondents, including age, race, ethnicity, and
sex.

\subsection{Simulations}

For our simulation approach, we run iterations of a disclosure mechanism
to generate noisy histograms of counts for a set of defined attributes.
We focus on two disclosure mechanisms to compare a standard global
approach to a local opt-in approach. The first is a Laplace sanitizer, a
global method in which cells are infused with noise from a Laplace
distribution. The Laplace distribution is centered at zero and the
variability is the ratio of the privacy loss budget, \(\epsilon\), over
the \(l_1\)-global sensitivity of the statistic {[}Dwork et al.
(2006){]}(Williams and Bowen 2023). The second is the previously
described GRR method, a local method in which individuals who opt in to
disclosure protections report a true response with probability
\(p = \frac{e^\epsilon}{e^\epsilon + d - 1}\). Otherwise, the record is
randomly replaced with another combination of fields.~

We then evaluate these results using bias and accuracy metrics,
comparing the noisy histograms to the true values. We use mean percent
error to evaluate bias, or the tendency for noisy estimates to
systematically move in one direction relative to the true values. We use
absolute mean percent error to evaluate accuracy, or the closeness of
noisy estimates to the true values.~

The specifications for our simulations are as follows. For each
combination of specifications, we run 100 iterations of each disclosure
mechanism.

\begin{itemize}
\tightlist
\item
  Scenarios: the set of grouping attributes for the resulting histogram
  frequencies

  \begin{itemize}
  \tightlist
  \item
    Scenario 1 (cardinality = 2)

    \begin{itemize}
    \tightlist
    \item
      Hispanicity: Hispanic or Latino, Not Hispanic or Latino
    \end{itemize}
  \item
    Scenario 2 (cardinality = 24)

    \begin{itemize}
    \item
      Age bucket: Child (0-17), Adult (18-64), Senior (65+)
    \item
      Race/Ethnicity: White alone, Black or African American alone,
      Other alone, or Hispanic or Latino (any race)
    \item
      Sex: Male, Female
    \end{itemize}
  \end{itemize}
\item
  Privacy loss budget, \(\epsilon\)

  \begin{itemize}
  \tightlist
  \item
    1
  \item
    5
  \item
    10
  \item
    20
  \end{itemize}
\item
  Opt-in rate: the probability that respondents opt in to disclosure
  protections

  \begin{itemize}
  \item
    0.01
  \item
    0.1
  \item
    0.5
  \item
    0.9
  \item
    1
  \end{itemize}
\end{itemize}

\subsection{Results and Discussion}

\textbf{Local DP Methods Result in Overall Lower Accuracy than Global
Methods}

For Scenario 1, we focus primarily on results allowing us to compare the
performance of the local GRR method to the central Laplace method. With
a cardinality of just 2 (Hispanic or Latino, Not Hispanic or Latino),
this scenario allows for the most similar comparison with the global
method (in which epsilon is allocated to just one statistic).~

Figure \ref{fig:methods-bias} shows the distribution of bias metrics
from our simulations at the defined levels of \(\epsilon\) and opt in
rate. Both the local and central methods are unbiased, with the
distribution of mean percent error values centered around zero.~

\begin{figure}[!htb]
    \centering
    \caption{Local and Central DP Approaches are Similarly Unbiased}
    \includegraphics[width=4in]{../figures/methods_bias.png}
    \label{fig:methods-bias}
\end{figure}

Figure \ref{fig:methods-accuracy} shows the distribution of accuracy
metrics from our simulations at the defined levels of epsilon and opt in
rate.~

\begin{figure}[!htb]
    \centering
    \caption{Local Method Outperforms Central Method Only with Very High Privacy Loss Budget}
    \includegraphics[width=4in]{../figures/methods_accuracy.png}
    \label{fig:methods-accuracy}
\end{figure}

Figure \ref{fig:methods-accuracy} demonstrates two key takeaways about
the accuracy of these methods. First, the opt-in framework approach does
improve the overall accuracy of the local GRR method. As we decrease the
level of opt in, the width of the mean percent error distribution
shrinks and moves closer to zero. However, the second key takeaway is
that the central method significantly outperforms the local method in
terms of accuracy at nearly every tested level of \(\epsilon\) and opt
in rate, even with very small opt in rates. The local method only
outperforms the central method with a very high privacy loss budget of
\(\epsilon\) = 20, and the errors for both methods are very small for
that level of privacy loss anyway.~

While the opt-in local approach does improve the accuracy of estimates
with lower levels of opt in, this improvement alone is unfortunately not
enough to justify a switch from a central model to a local model.
Existing local DP methods cannot offer the same level of accuracy as
central methods, especially for datasets with even higher cardinality.
However, the potential to improve data quality results with a local
method and opt-in framework motivates greater focus on developing local
DP methods in the future.~

\textbf{Opt-in Privacy Offers the Potential to Improve Data Quality for
Small Groups}

Although existing local DP methods may be disappointing for overall
accuracy, an opt-in local DP framework still offers the potential to
improve data quality for small groups. Data quality may be especially
improved for groups that opt-in at relatively lower rates than others.
For Scenario 2, we focus on results allowing us to compare differences
in data quality by racial/ethnic group.~

Figures \ref{fig:groups_dc} and \ref{fig:groups_ia} show the
distribution of accuracy results for the specified opt in rates for each
racial/ethnic group (using \(\epsilon\) = 1), separately by state.

\begin{figure}[!htb]
    \centering
    \caption{Accuracy By Racial/Ethnic Group, Washington, DC}
    \includegraphics[width=4in]{../figures/groups_dc.png}
    \label{fig:groups_dc}
\end{figure}

\begin{figure}[!htb]
    \centering
    \caption{Accuracy By Racial/Ethnic Group, Iowa}
    \includegraphics[width=4in]{../figures/groups_ia.png}
    \label{fig:groups_ia}
\end{figure}

According to the 2010 Census Redistricting Data (Public Law 94-171)
Summary File, the population of Washington DC was 38\% white,
non-Hispanic and 51\% Black, non-Hispanic, and the population of Iowa
was 91\% white, non-Hispanic. For both states, mean percent error is
smallest for these relatively large groups, reflecting the larger sample
sizes. Error tends to be relatively larger, and with larger spreads, for
the smaller groups in both places.

The opt-in framework offers a solution path to improve data accuracy for
these smaller racial/ethnic groups. For example, the median absolute
percent error for the Hispanic group is roughly 3.5\% in Washington, DC
and 6\% in Iowa when there is 100\% opt in, or when all respondents are
subjected to disclosure protections. These error values shrink to about
1.5\% and 2\%, respectively, with a group opt-in rate of 10\%. Given the
properties of formal privacy, the privacy protections afforded to those
who opt-in are unaffected by those who choose to forego protections.

With an opt-in disclosure framework, the US Census Bureau and community
groups could engage in outreach efforts, especially to smaller groups,
to help respondents understand the implications of foregoing disclosure
protections, both for their privacy but also for the wide-ranging
impacts of improving their data quality. This type of outreach could
result in better data quality for these groups, with positive downstream
impacts on representation and funding allocations to communities.~

All in all, existing local DP methods generate protected data of overall
lower accuracy than data generated by central models. However, this
demonstration shows the potential of local DP to improve data accuracy
for small groups, while still protecting privacy, with an opt-in DP
framework. This use case motivates further development of local DP
methods and opt in experimentation to improve accuracy results.~

\section{Demonstration 2: Synthetic Data for the American Community Survey}

\subsection{Synthetic Data}

\subsection{Data}

\subsection{Simulations}

\subsection{Results and Discussion}

\section{Conclusion}

\include{backmatter/appendix}

\include{backmatter/notes}

\include{backmatter/references}

\include{backmatter/author}

\include{backmatter/independence}

\newpage
\thispagestyle{empty}

\begin{textblock*}{8.5in}[1, 1](8.5in, 11in)
    \noindent\includegraphics[width=\paperwidth,height=\paperheight]{images/back.pdf}
\end{textblock*}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-abowd2018}{}}%
Abowd, John M. 2018. {``Protecting the Confidentiality of Americas
Statistics: Adopting Modern Disclosure Avoidance Methods at the Census
Bureau.''}
\url{https://www.census.gov/newsroom/blogs/research-matters/2018/08/protecting_the_confi.html}.

\leavevmode\vadjust pre{\hypertarget{ref-abowd2022a}{}}%
Abowd, John, Robert Ashmead, Ryan Cumings-Menon, Simson Garfinkel, Micah
Heineck, Christine Heiss, Robert Johns, et al. 2022. {``The 2020 Census
Disclosure Avoidance System TopDown Algorithm.''} \emph{Harvard Data
Science Review}, no. Special Issue 2 (June).
\url{https://doi.org/10.1162/99608f92.529e3cb9}.

\leavevmode\vadjust pre{\hypertarget{ref-axelrod2022}{}}%
Axelrod, Judah, Karolina Ramos, and Rebecca Bullied. 2022.
{``Opportunities and Challenges in Using Private-Sector Data for Racial
Equity Analysis.''}

\leavevmode\vadjust pre{\hypertarget{ref-bowen2022}{}}%
Bowen, Claire McKay, Aaron R Williams, and Madeline Pickens. 2022.
{``Decennial Disclosure: An Explainer on Formal Privacy and the TopDown
Algorithm.''}

\leavevmode\vadjust pre{\hypertarget{ref-daily2022a}{}}%
Daily, Donna. 2022. {``Disclosure Avoidance Protections for the American
Community Survey.''}
\url{https://www.census.gov/newsroom/blogs/random-samplings/2022/12/disclosure-avoidance-protections-acs.html}.

\leavevmode\vadjust pre{\hypertarget{ref-dwork2006c}{}}%
Dwork, Cynthia, Frank McSherry, Kobbi Nissim, and Adam Smith. 2006.
{``Calibrating Noise to Sensitivity in Private Data Analysis.''} In,
edited by Shai Halevi and Tal Rabin, 3876:265--84. Berlin, Heidelberg:
Springer Berlin Heidelberg.
\url{http://link.springer.com/10.1007/11681878_14}.

\leavevmode\vadjust pre{\hypertarget{ref-hotchkiss2017a}{}}%
Hotchkiss, Marisa, and Jessica Phelan. 2017. {``Uses of Census Bureau
Data in Federal Funds Distribution: A New Design for the 21st
Century,''} September.
\url{https://www2.census.gov/programs-surveys/decennial/2020/program-management/working-papers/Uses-of-Census-Bureau-Data-in-Federal-Funds-Distribution.pdf}.

\leavevmode\vadjust pre{\hypertarget{ref-hotz2022a}{}}%
Hotz, V. Joseph, and Joseph Salvo. 2022. {``A Chronicle of the
Application of Differential Privacy to the 2020 Census.''} \emph{Harvard
Data Science Review}, June.
\url{https://doi.org/10.1162/99608f92.ff891fe5}.

\leavevmode\vadjust pre{\hypertarget{ref-mather2019a}{}}%
Mather, Mark, and Paola Scommegna. 2019. {``Why Is the u.s. Census so
Important?''} March.
\url{https://www.prb.org/resources/importance-of-u-s-census/}.

\leavevmode\vadjust pre{\hypertarget{ref-near2022}{}}%
Near, Joseph P, and Chik√© Abuah. 2022. \emph{Programming Differential
Privacy}.

\leavevmode\vadjust pre{\hypertarget{ref-unitedstatescensusbureau2017}{}}%
United States Census Bureau. 2017. {``American Community Survey
Information Guide,''} October.

\leavevmode\vadjust pre{\hypertarget{ref-wang2020a}{}}%
Wang, Teng, Xuefeng Zhang, Jingyu Feng, and Xinyu Yang. 2020. {``A
Comprehensive Survey on Local Differential Privacy Toward Data
Statistics and Analysis.''} \emph{Sensors} 20 (24): 7030.
\url{https://doi.org/10.3390/s20247030}.

\leavevmode\vadjust pre{\hypertarget{ref-warner1965a}{}}%
Warner, Stanley L. 1965. {``Randomized Response: A Survey Technique for
Eliminating Evasive Answer Bias.''} \emph{Journal of the American
Statistical Association} 60 (309): 63--69.
\url{https://doi.org/10.1080/01621459.1965.10480775}.

\leavevmode\vadjust pre{\hypertarget{ref-williams2023a}{}}%
Williams, Aaron R., and Claire McKay Bowen. 2023. {``The Promise and
Limitations of Formal Privacy.''} \emph{WIREs Computational Statistics},
May, e1615. \url{https://doi.org/10.1002/wics.1615}.

\end{CSLReferences}



\newpage
\thispagestyle{empty}

\begin{textblock*}{8.5in}[1, 1](8.5in, 11in)
    \noindent\includegraphics[width=\paperwidth,height=\paperheight]{images/back.pdf}
\end{textblock*}

\end{document}

\end{document}
